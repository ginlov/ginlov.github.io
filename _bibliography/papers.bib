---
---

---
---

@article{vu2024on,
  abbr={AAAI},
  title={On Inference Stability for Diffusion Models},
  author={Vu*, Giang and Nguyen*, Viet and Nguyen Thanh, Tung and Than, Khoat and Tran, Toan},
  abstract={Denoising Probabilistic Models (DPMs) represent an emerging domain of generative models that excel in generating di- verse and high-quality images. However, most current training methods for DPMs often neglect the correlation between timesteps, limiting the modelâ€™s performance in generating images effectively. Notably, we theoretically point out that this issue can be caused by the cumulative estimation gap between the predicted and the actual trajectory. To minimize that gap, we propose a novel sequence-aware loss that aims to reduce the estimation gap to enhance the sampling quality. Furthermore, we theoretically show that our proposed loss function is a tighter upper bound of the estimation loss in comparison with the conventional loss in DPMs. Experimental results on several benchmark datasets including CIFAR10, CelebA, and CelebA-HQ consistently show a remarkable improvement of our proposed method regarding the image generalization quality measured by FID and Inception Score compared to several DPM baselines. Our code and pre-trained checkpoints are available at https://github.com/VinAIResearch/SA-DPM.},
  journal={AAAI Conference on Artificial Intelligence},
  award={Oral Presentation},
  award_name={Oral},
  honor={Oral Presentation},
  year={2024},
  url={https://arxiv.org/abs/2312.12431},
  pdf={https://arxiv.org/pdf/2312.12431.pdf},
  selected={true},
  google_scholar_id={uc_IGeMz5qoC},
  published={false}
}

@article{vu2025gentle,
    author = {Than, Khoat and Phan, Dat and Vu, Giang},
    abbr= {SNML},
    abstract = {Robustness and generalization ability of machine learning models are of utmost
importance in various application domains. There is a wide interest in efficient
ways to analyze those properties. One important direction is to analyze connection between those two properties. Prior theories suggest that a robust learning
algorithm can produce trained models with a high generalization ability. However,
we show in this work that the existing error bounds are vacuous for the Bayes
optimal classifier which is the best among all measurable classifiers for a classification problem with overlapping classes. Those bounds cannot converge to the
true error of this ideal classifier. This is undesirable, surprizing, and never known
before. We then present a class of novel bounds, which are model-dependent and
provably tighter than the existing robustness-based ones. Unlike prior ones, our
bounds are guaranteed to converge to the true error of the best classifier, as the
number of samples increases. We further provide an extensive experiment and
find that two of our bounds are often non-vacuous for a large class of deep neural
networks, pretrained from ImageNet.},
    title = {Gentle Local Robustness implies Generalization},
    journal = {Springer Nature Machine Learning},
    year = {2025},
    selected={true},
    google_scholar_id={EkHepimYqZsC},
    url={https://arxiv.org/abs/2412.06381},
    pdf={https://arxiv.org/abs/2412.06381.pdf}
}